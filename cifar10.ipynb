{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from batch 1\n",
      "Getting data from batch 2\n",
      "Getting data from batch 3\n",
      "Getting data from batch 4\n",
      "Getting data from batch 5\n",
      "Train Data shape:  (50000, 3072)\n",
      "Train Label shape:  (50000,)\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './tmp/mnist_classifier', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x111ee1860>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "batch size:  128\n",
      "input data shape:  Tensor(\"random_shuffle_queue_DequeueUpTo:1\", shape=(?, 3072), dtype=float32, device=/device:CPU:0)\n",
      "input layer shape:  (?, 32, 32, 3)\n",
      "pool1 shape:  Tensor(\"pool1:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "pool2 shape:  Tensor(\"pool2:0\", shape=(?, 8, 8, 64), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./tmp/mnist_classifier/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.10720724]\n",
      " [ 0.          0.          0.         ...,  0.          0.          1.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.99999201  0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.00000029 ...,  0.          0.00000012  0.        ]]\n",
      "INFO:tensorflow:loss = 50.0776, step = 1\n",
      "INFO:tensorflow:probabilities = [[ 0.1010248   0.09805956  0.09968444 ...,  0.10125118  0.10133472\n",
      "   0.09914347]\n",
      " [ 0.1010248   0.09805956  0.09968444 ...,  0.10125118  0.10133472\n",
      "   0.09914347]\n",
      " [ 0.1010248   0.09805956  0.09968444 ...,  0.10125118  0.10133472\n",
      "   0.09914347]\n",
      " ..., \n",
      " [ 0.1010248   0.09805956  0.09968444 ...,  0.10125118  0.10133472\n",
      "   0.09914347]\n",
      " [ 0.1010248   0.09805956  0.09968444 ...,  0.10125118  0.10133472\n",
      "   0.09914347]\n",
      " [ 0.1010248   0.09805956  0.09968444 ...,  0.10125118  0.10133472\n",
      "   0.09914347]] (29.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.68479\n",
      "INFO:tensorflow:probabilities = [[ 0.10072153  0.09814222  0.09970051 ...,  0.10108092  0.1013182\n",
      "   0.09918981]\n",
      " [ 0.10072153  0.09814222  0.09970051 ...,  0.10108092  0.1013182\n",
      "   0.09918981]\n",
      " [ 0.10072153  0.09814222  0.09970051 ...,  0.10108092  0.1013182\n",
      "   0.09918981]\n",
      " ..., \n",
      " [ 0.10072153  0.09814222  0.09970051 ...,  0.10108092  0.1013182\n",
      "   0.09918981]\n",
      " [ 0.10072153  0.09814222  0.09970051 ...,  0.10108092  0.1013182\n",
      "   0.09918981]\n",
      " [ 0.10072153  0.09814222  0.09970051 ...,  0.10108092  0.1013182\n",
      "   0.09918981]] (29.547 sec)\n",
      "INFO:tensorflow:loss = 2.3018, step = 101 (59.356 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10089281  0.09808806  0.09991783 ...,  0.10098237  0.10122447\n",
      "   0.09929924]\n",
      " [ 0.10089281  0.09808806  0.09991783 ...,  0.10098237  0.10122447\n",
      "   0.09929924]\n",
      " [ 0.10089281  0.09808806  0.09991783 ...,  0.10098237  0.10122447\n",
      "   0.09929924]\n",
      " ..., \n",
      " [ 0.10089281  0.09808806  0.09991783 ...,  0.10098237  0.10122447\n",
      "   0.09929924]\n",
      " [ 0.10089281  0.09808806  0.09991783 ...,  0.10098237  0.10122447\n",
      "   0.09929924]\n",
      " [ 0.10089281  0.09808806  0.09991783 ...,  0.10098237  0.10122447\n",
      "   0.09929924]] (29.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71101\n",
      "INFO:tensorflow:probabilities = [[ 0.10099054  0.09824045  0.09962732 ...,  0.10079598  0.10099761\n",
      "   0.09935994]\n",
      " [ 0.10099054  0.09824045  0.09962732 ...,  0.10079598  0.10099761\n",
      "   0.09935994]\n",
      " [ 0.10099054  0.09824045  0.09962732 ...,  0.10079598  0.10099761\n",
      "   0.09935994]\n",
      " ..., \n",
      " [ 0.10099054  0.09824045  0.09962732 ...,  0.10079598  0.10099761\n",
      "   0.09935994]\n",
      " [ 0.10099054  0.09824045  0.09962732 ...,  0.10079598  0.10099761\n",
      "   0.09935994]\n",
      " [ 0.10099054  0.09824045  0.09962732 ...,  0.10079598  0.10099761\n",
      "   0.09935994]] (29.168 sec)\n",
      "INFO:tensorflow:loss = 2.30256, step = 201 (58.445 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10088831  0.09823175  0.09964745 ...,  0.10065674  0.10119297\n",
      "   0.09948099]\n",
      " [ 0.10088831  0.09823175  0.09964745 ...,  0.10065674  0.10119297\n",
      "   0.09948099]\n",
      " [ 0.10088831  0.09823175  0.09964745 ...,  0.10065674  0.10119297\n",
      "   0.09948099]\n",
      " ..., \n",
      " [ 0.10088831  0.09823175  0.09964745 ...,  0.10065674  0.10119297\n",
      "   0.09948099]\n",
      " [ 0.10088831  0.09823175  0.09964745 ...,  0.10065674  0.10119297\n",
      "   0.09948099]\n",
      " [ 0.10088831  0.09823175  0.09964745 ...,  0.10065674  0.10119297\n",
      "   0.09948099]] (29.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.70961\n",
      "INFO:tensorflow:probabilities = [[ 0.1009226   0.09834495  0.09976534 ...,  0.10063131  0.10131197\n",
      "   0.09931335]\n",
      " [ 0.1009226   0.09834495  0.09976534 ...,  0.10063131  0.10131197\n",
      "   0.09931335]\n",
      " [ 0.1009226   0.09834495  0.09976534 ...,  0.10063131  0.10131197\n",
      "   0.09931335]\n",
      " ..., \n",
      " [ 0.1009226   0.09834495  0.09976534 ...,  0.10063131  0.10131197\n",
      "   0.09931335]\n",
      " [ 0.1009226   0.09834495  0.09976534 ...,  0.10063131  0.10131197\n",
      "   0.09931335]\n",
      " [ 0.1009226   0.09834495  0.09976534 ...,  0.10063131  0.10131197\n",
      "   0.09931335]] (29.256 sec)\n",
      "INFO:tensorflow:loss = 2.30288, step = 301 (58.493 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10087415  0.09851074  0.09979668 ...,  0.1008324   0.10115492\n",
      "   0.09916947]\n",
      " [ 0.10087415  0.09851074  0.09979668 ...,  0.1008324   0.10115492\n",
      "   0.09916947]\n",
      " [ 0.10087415  0.09851074  0.09979668 ...,  0.1008324   0.10115492\n",
      "   0.09916947]\n",
      " ..., \n",
      " [ 0.10087415  0.09851074  0.09979668 ...,  0.1008324   0.10115492\n",
      "   0.09916947]\n",
      " [ 0.10087415  0.09851074  0.09979668 ...,  0.1008324   0.10115492\n",
      "   0.09916947]\n",
      " [ 0.10087415  0.09851074  0.09979668 ...,  0.1008324   0.10115492\n",
      "   0.09916947]] (29.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71133\n",
      "INFO:tensorflow:probabilities = [[ 0.10070153  0.09867824  0.09976444 ...,  0.10072207  0.10098775\n",
      "   0.09932718]\n",
      " [ 0.10070153  0.09867824  0.09976444 ...,  0.10072207  0.10098775\n",
      "   0.09932718]\n",
      " [ 0.10070153  0.09867824  0.09976444 ...,  0.10072207  0.10098775\n",
      "   0.09932718]\n",
      " ..., \n",
      " [ 0.10070153  0.09867824  0.09976444 ...,  0.10072207  0.10098775\n",
      "   0.09932718]\n",
      " [ 0.10070153  0.09867824  0.09976444 ...,  0.10072207  0.10098775\n",
      "   0.09932718]\n",
      " [ 0.10070153  0.09867824  0.09976444 ...,  0.10072207  0.10098775\n",
      "   0.09932718]] (29.149 sec)\n",
      "INFO:tensorflow:loss = 2.30271, step = 401 (58.434 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10059546  0.09876281  0.09965981 ...,  0.10083319  0.1007127\n",
      "   0.09949949]\n",
      " [ 0.10059546  0.09876281  0.09965981 ...,  0.10083319  0.1007127\n",
      "   0.09949949]\n",
      " [ 0.10059546  0.09876281  0.09965981 ...,  0.10083319  0.1007127\n",
      "   0.09949949]\n",
      " ..., \n",
      " [ 0.10059546  0.09876281  0.09965981 ...,  0.10083319  0.1007127\n",
      "   0.09949949]\n",
      " [ 0.10059546  0.09876281  0.09965981 ...,  0.10083319  0.1007127\n",
      "   0.09949949]\n",
      " [ 0.10059546  0.09876281  0.09965981 ...,  0.10083319  0.1007127\n",
      "   0.09949949]] (29.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71137\n",
      "INFO:tensorflow:probabilities = [[ 0.1005373   0.09873667  0.09998055 ...,  0.10071306  0.10087404\n",
      "   0.09950028]\n",
      " [ 0.1005373   0.09873667  0.09998055 ...,  0.10071306  0.10087404\n",
      "   0.09950028]\n",
      " [ 0.1005373   0.09873667  0.09998055 ...,  0.10071306  0.10087404\n",
      "   0.09950028]\n",
      " ..., \n",
      " [ 0.1005373   0.09873667  0.09998055 ...,  0.10071306  0.10087404\n",
      "   0.09950028]\n",
      " [ 0.1005373   0.09873667  0.09998055 ...,  0.10071306  0.10087404\n",
      "   0.09950028]\n",
      " [ 0.1005373   0.09873667  0.09998055 ...,  0.10071306  0.10087404\n",
      "   0.09950028]] (29.206 sec)\n",
      "INFO:tensorflow:loss = 2.30313, step = 501 (58.433 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10061259  0.09876187  0.09987791 ...,  0.10060818  0.1008112\n",
      "   0.09948055]\n",
      " [ 0.10061259  0.09876187  0.09987791 ...,  0.10060818  0.1008112\n",
      "   0.09948055]\n",
      " [ 0.10061259  0.09876187  0.09987791 ...,  0.10060818  0.1008112\n",
      "   0.09948055]\n",
      " ..., \n",
      " [ 0.10061259  0.09876187  0.09987791 ...,  0.10060818  0.1008112\n",
      "   0.09948055]\n",
      " [ 0.10061259  0.09876187  0.09987791 ...,  0.10060818  0.1008112\n",
      "   0.09948055]\n",
      " [ 0.10061259  0.09876187  0.09987791 ...,  0.10060818  0.1008112\n",
      "   0.09948055]] (29.352 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.70553\n",
      "INFO:tensorflow:probabilities = [[ 0.10076835  0.0987554   0.09970039 ...,  0.10043164  0.10070011\n",
      "   0.09964534]\n",
      " [ 0.10076835  0.0987554   0.09970039 ...,  0.10043164  0.10070011\n",
      "   0.09964534]\n",
      " [ 0.10076835  0.0987554   0.09970039 ...,  0.10043164  0.10070011\n",
      "   0.09964534]\n",
      " ..., \n",
      " [ 0.10076835  0.0987554   0.09970039 ...,  0.10043164  0.10070011\n",
      "   0.09964534]\n",
      " [ 0.10076835  0.0987554   0.09970039 ...,  0.10043164  0.10070011\n",
      "   0.09964534]\n",
      " [ 0.10076835  0.0987554   0.09970039 ...,  0.10043164  0.10070011\n",
      "   0.09964534]] (29.281 sec)\n",
      "INFO:tensorflow:loss = 2.30373, step = 601 (58.633 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10076734  0.09863591  0.0997754  ...,  0.10039594  0.10080401\n",
      "   0.0996612 ]\n",
      " [ 0.10076734  0.09863591  0.0997754  ...,  0.10039594  0.10080401\n",
      "   0.0996612 ]\n",
      " [ 0.10076734  0.09863591  0.0997754  ...,  0.10039594  0.10080401\n",
      "   0.0996612 ]\n",
      " ..., \n",
      " [ 0.10076734  0.09863591  0.0997754  ...,  0.10039594  0.10080401\n",
      "   0.0996612 ]\n",
      " [ 0.10076734  0.09863591  0.0997754  ...,  0.10039594  0.10080401\n",
      "   0.0996612 ]\n",
      " [ 0.10076734  0.09863591  0.0997754  ...,  0.10039594  0.10080401\n",
      "   0.0996612 ]] (29.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71346\n",
      "INFO:tensorflow:probabilities = [[ 0.10059265  0.09865578  0.09973301 ...,  0.10061003  0.10091069\n",
      "   0.09944012]\n",
      " [ 0.10059265  0.09865578  0.09973301 ...,  0.10061003  0.10091069\n",
      "   0.09944012]\n",
      " [ 0.10059265  0.09865578  0.09973301 ...,  0.10061003  0.10091069\n",
      "   0.09944012]\n",
      " ..., \n",
      " [ 0.10059265  0.09865578  0.09973301 ...,  0.10061003  0.10091069\n",
      "   0.09944012]\n",
      " [ 0.10059265  0.09865578  0.09973301 ...,  0.10061003  0.10091069\n",
      "   0.09944012]\n",
      " [ 0.10059265  0.09865578  0.09973301 ...,  0.10061003  0.10091069\n",
      "   0.09944012]] (29.233 sec)\n",
      "INFO:tensorflow:loss = 2.30354, step = 701 (58.362 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10052305  0.09899289  0.09995548 ...,  0.10058299  0.10083782\n",
      "   0.09936912]\n",
      " [ 0.10052305  0.09899289  0.09995548 ...,  0.10058299  0.10083782\n",
      "   0.09936912]\n",
      " [ 0.10052305  0.09899289  0.09995548 ...,  0.10058299  0.10083782\n",
      "   0.09936912]\n",
      " ..., \n",
      " [ 0.10052305  0.09899289  0.09995548 ...,  0.10058299  0.10083782\n",
      "   0.09936912]\n",
      " [ 0.10052305  0.09899289  0.09995548 ...,  0.10058299  0.10083782\n",
      "   0.09936912]\n",
      " [ 0.10052305  0.09899289  0.09995548 ...,  0.10058299  0.10083782\n",
      "   0.09936912]] (29.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71322\n",
      "INFO:tensorflow:probabilities = [[ 0.10042835  0.0992128   0.09990308 ...,  0.1005739   0.10071326\n",
      "   0.09953757]\n",
      " [ 0.10042835  0.0992128   0.09990308 ...,  0.1005739   0.10071326\n",
      "   0.09953757]\n",
      " [ 0.10042835  0.0992128   0.09990308 ...,  0.1005739   0.10071326\n",
      "   0.09953757]\n",
      " ..., \n",
      " [ 0.10042835  0.0992128   0.09990308 ...,  0.1005739   0.10071326\n",
      "   0.09953757]\n",
      " [ 0.10042835  0.0992128   0.09990308 ...,  0.1005739   0.10071326\n",
      "   0.09953757]\n",
      " [ 0.10042835  0.0992128   0.09990308 ...,  0.1005739   0.10071326\n",
      "   0.09953757]] (29.164 sec)\n",
      "INFO:tensorflow:loss = 2.30257, step = 801 (58.369 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10035096  0.09934794  0.09971766 ...,  0.10063752  0.10037211\n",
      "   0.09967394]\n",
      " [ 0.10035096  0.09934794  0.09971766 ...,  0.10063752  0.10037211\n",
      "   0.09967394]\n",
      " [ 0.10035096  0.09934794  0.09971766 ...,  0.10063752  0.10037211\n",
      "   0.09967394]\n",
      " ..., \n",
      " [ 0.10035096  0.09934794  0.09971766 ...,  0.10063752  0.10037211\n",
      "   0.09967394]\n",
      " [ 0.10035096  0.09934794  0.09971766 ...,  0.10063752  0.10037211\n",
      "   0.09967394]\n",
      " [ 0.10035096  0.09934794  0.09971766 ...,  0.10063752  0.10037211\n",
      "   0.09967394]] (29.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71167\n",
      "INFO:tensorflow:probabilities = [[ 0.10036741  0.09916442  0.10008988 ...,  0.10041369  0.10048532\n",
      "   0.09957454]\n",
      " [ 0.10036741  0.09916442  0.10008988 ...,  0.10041369  0.10048532\n",
      "   0.09957454]\n",
      " [ 0.10036741  0.09916442  0.10008988 ...,  0.10041369  0.10048532\n",
      "   0.09957454]\n",
      " ..., \n",
      " [ 0.10036741  0.09916442  0.10008988 ...,  0.10041369  0.10048532\n",
      "   0.09957454]\n",
      " [ 0.10036741  0.09916442  0.10008988 ...,  0.10041369  0.10048532\n",
      "   0.09957454]\n",
      " [ 0.10036741  0.09916442  0.10008988 ...,  0.10041369  0.10048532\n",
      "   0.09957454]] (29.253 sec)\n",
      "INFO:tensorflow:loss = 2.3023, step = 901 (58.423 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10041847  0.09925335  0.09997112 ...,  0.10044397  0.10054634\n",
      "   0.09974118]\n",
      " [ 0.10041847  0.09925335  0.09997112 ...,  0.10044397  0.10054634\n",
      "   0.09974118]\n",
      " [ 0.10041847  0.09925335  0.09997112 ...,  0.10044397  0.10054634\n",
      "   0.09974118]\n",
      " ..., \n",
      " [ 0.10041847  0.09925335  0.09997112 ...,  0.10044397  0.10054634\n",
      "   0.09974118]\n",
      " [ 0.10041847  0.09925335  0.09997112 ...,  0.10044397  0.10054634\n",
      "   0.09974118]\n",
      " [ 0.10041847  0.09925335  0.09997112 ...,  0.10044397  0.10054634\n",
      "   0.09974118]] (29.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7095\n",
      "INFO:tensorflow:probabilities = [[ 0.10055744  0.09924386  0.09973743 ...,  0.10031535  0.10048971\n",
      "   0.09971758]\n",
      " [ 0.10055744  0.09924386  0.09973743 ...,  0.10031535  0.10048971\n",
      "   0.09971758]\n",
      " [ 0.10055744  0.09924386  0.09973743 ...,  0.10031535  0.10048971\n",
      "   0.09971758]\n",
      " ..., \n",
      " [ 0.10055744  0.09924386  0.09973743 ...,  0.10031535  0.10048971\n",
      "   0.09971758]\n",
      " [ 0.10055744  0.09924386  0.09973743 ...,  0.10031535  0.10048971\n",
      "   0.09971758]\n",
      " [ 0.10055744  0.09924386  0.09973743 ...,  0.10031535  0.10048971\n",
      "   0.09971758]] (29.260 sec)\n",
      "INFO:tensorflow:loss = 2.30391, step = 1001 (58.497 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1026 into ./tmp/mnist_classifier/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.10047016  0.09896678  0.09980249 ...,  0.10020209  0.10053175\n",
      "   0.09998475]\n",
      " [ 0.10047016  0.09896678  0.09980249 ...,  0.10020209  0.10053175\n",
      "   0.09998475]\n",
      " [ 0.10047016  0.09896678  0.09980249 ...,  0.10020209  0.10053175\n",
      "   0.09998475]\n",
      " ..., \n",
      " [ 0.10047016  0.09896678  0.09980249 ...,  0.10020209  0.10053175\n",
      "   0.09998475]\n",
      " [ 0.10047016  0.09896678  0.09980249 ...,  0.10020209  0.10053175\n",
      "   0.09998475]\n",
      " [ 0.10047016  0.09896678  0.09980249 ...,  0.10020209  0.10053175\n",
      "   0.09998475]] (29.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.70625\n",
      "INFO:tensorflow:probabilities = [[ 0.10048654  0.09913574  0.09987427 ...,  0.10029713  0.10077439\n",
      "   0.09956229]\n",
      " [ 0.10048654  0.09913574  0.09987427 ...,  0.10029713  0.10077439\n",
      "   0.09956229]\n",
      " [ 0.10048654  0.09913574  0.09987427 ...,  0.10029713  0.10077439\n",
      "   0.09956229]\n",
      " ..., \n",
      " [ 0.10048654  0.09913574  0.09987427 ...,  0.10029713  0.10077439\n",
      "   0.09956229]\n",
      " [ 0.10048654  0.09913574  0.09987427 ...,  0.10029713  0.10077439\n",
      "   0.09956229]\n",
      " [ 0.10048654  0.09913574  0.09987427 ...,  0.10029713  0.10077439\n",
      "   0.09956229]] (29.156 sec)\n",
      "INFO:tensorflow:loss = 2.3031, step = 1101 (58.608 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10041035  0.09921163  0.09996076 ...,  0.10047525  0.10060106\n",
      "   0.09939922]\n",
      " [ 0.10041035  0.09921163  0.09996076 ...,  0.10047525  0.10060106\n",
      "   0.09939922]\n",
      " [ 0.10041035  0.09921163  0.09996076 ...,  0.10047525  0.10060106\n",
      "   0.09939922]\n",
      " ..., \n",
      " [ 0.10041035  0.09921163  0.09996076 ...,  0.10047525  0.10060106\n",
      "   0.09939922]\n",
      " [ 0.10041035  0.09921163  0.09996076 ...,  0.10047525  0.10060106\n",
      "   0.09939922]\n",
      " [ 0.10041035  0.09921163  0.09996076 ...,  0.10047525  0.10060106\n",
      "   0.09939922]] (29.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.70808\n",
      "INFO:tensorflow:probabilities = [[ 0.1004421   0.09949869  0.09984831 ...,  0.10050838  0.10043351\n",
      "   0.09960003]\n",
      " [ 0.1004421   0.09949869  0.09984831 ...,  0.10050838  0.10043351\n",
      "   0.09960003]\n",
      " [ 0.1004421   0.09949869  0.09984831 ...,  0.10050838  0.10043351\n",
      "   0.09960003]\n",
      " ..., \n",
      " [ 0.1004421   0.09949869  0.09984831 ...,  0.10050838  0.10043351\n",
      "   0.09960003]\n",
      " [ 0.1004421   0.09949869  0.09984831 ...,  0.10050838  0.10043351\n",
      "   0.09960003]\n",
      " [ 0.1004421   0.09949869  0.09984831 ...,  0.10050838  0.10043351\n",
      "   0.09960003]] (29.197 sec)\n",
      "INFO:tensorflow:loss = 2.30243, step = 1201 (58.545 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10009181  0.09963905  0.09987908 ...,  0.10054657  0.10031554\n",
      "   0.09973769]\n",
      " [ 0.10009181  0.09963905  0.09987908 ...,  0.10054657  0.10031554\n",
      "   0.09973769]\n",
      " [ 0.10009181  0.09963905  0.09987908 ...,  0.10054657  0.10031554\n",
      "   0.09973769]\n",
      " ..., \n",
      " [ 0.10009181  0.09963905  0.09987908 ...,  0.10054657  0.10031554\n",
      "   0.09973769]\n",
      " [ 0.10009181  0.09963905  0.09987908 ...,  0.10054657  0.10031554\n",
      "   0.09973769]\n",
      " [ 0.10009181  0.09963905  0.09987908 ...,  0.10054657  0.10031554\n",
      "   0.09973769]] (31.208 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.6114\n",
      "INFO:tensorflow:probabilities = [[ 0.10028001  0.0994311   0.10015399 ...,  0.10034579  0.10023483\n",
      "   0.09977295]\n",
      " [ 0.10028001  0.0994311   0.10015399 ...,  0.10034579  0.10023483\n",
      "   0.09977295]\n",
      " [ 0.10028001  0.0994311   0.10015399 ...,  0.10034579  0.10023483\n",
      "   0.09977295]\n",
      " ..., \n",
      " [ 0.10028001  0.0994311   0.10015399 ...,  0.10034579  0.10023483\n",
      "   0.09977295]\n",
      " [ 0.10028001  0.0994311   0.10015399 ...,  0.10034579  0.10023483\n",
      "   0.09977295]\n",
      " [ 0.10028001  0.0994311   0.10015399 ...,  0.10034579  0.10023483\n",
      "   0.09977295]] (30.850 sec)\n",
      "INFO:tensorflow:loss = 2.30293, step = 1301 (62.058 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.1003601   0.09962864  0.09988592 ...,  0.10019039  0.10020398\n",
      "   0.09977972]\n",
      " [ 0.1003601   0.09962864  0.09988592 ...,  0.10019039  0.10020398\n",
      "   0.09977972]\n",
      " [ 0.1003601   0.09962864  0.09988592 ...,  0.10019039  0.10020398\n",
      "   0.09977972]\n",
      " ..., \n",
      " [ 0.1003601   0.09962864  0.09988592 ...,  0.10019039  0.10020398\n",
      "   0.09977972]\n",
      " [ 0.1003601   0.09962864  0.09988592 ...,  0.10019039  0.10020398\n",
      "   0.09977972]\n",
      " [ 0.1003601   0.09962864  0.09988592 ...,  0.10019039  0.10020398\n",
      "   0.09977972]] (31.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5987\n",
      "INFO:tensorflow:probabilities = [[ 0.10034018  0.09948682  0.0996618  ...,  0.10008835  0.10033607\n",
      "   0.09997597]\n",
      " [ 0.10034018  0.09948682  0.0996618  ...,  0.10008835  0.10033607\n",
      "   0.09997597]\n",
      " [ 0.10034018  0.09948682  0.0996618  ...,  0.10008835  0.10033607\n",
      "   0.09997597]\n",
      " ..., \n",
      " [ 0.10034018  0.09948682  0.0996618  ...,  0.10008835  0.10033607\n",
      "   0.09997597]\n",
      " [ 0.10034018  0.09948682  0.0996618  ...,  0.10008835  0.10033607\n",
      "   0.09997597]\n",
      " [ 0.10034018  0.09948682  0.0996618  ...,  0.10008835  0.10033607\n",
      "   0.09997597]] (31.382 sec)\n",
      "INFO:tensorflow:loss = 2.30221, step = 1401 (62.551 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10023527  0.09924836  0.09992103 ...,  0.10016381  0.10044765\n",
      "   0.09994574]\n",
      " [ 0.10023527  0.09924836  0.09992103 ...,  0.10016381  0.10044765\n",
      "   0.09994574]\n",
      " [ 0.10023527  0.09924836  0.09992103 ...,  0.10016381  0.10044765\n",
      "   0.09994574]\n",
      " ..., \n",
      " [ 0.10023527  0.09924836  0.09992103 ...,  0.10016381  0.10044765\n",
      "   0.09994574]\n",
      " [ 0.10023527  0.09924836  0.09992103 ...,  0.10016381  0.10044765\n",
      "   0.09994574]\n",
      " [ 0.10023527  0.09924836  0.09992103 ...,  0.10016381  0.10044765\n",
      "   0.09994574]] (30.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.61777\n",
      "INFO:tensorflow:probabilities = [[ 0.10035914  0.09938388  0.09993573 ...,  0.10017724  0.10056877\n",
      "   0.09961468]\n",
      " [ 0.10035914  0.09938388  0.09993573 ...,  0.10017724  0.10056877\n",
      "   0.09961468]\n",
      " [ 0.10035914  0.09938388  0.09993573 ...,  0.10017724  0.10056877\n",
      "   0.09961468]\n",
      " ..., \n",
      " [ 0.10035914  0.09938388  0.09993573 ...,  0.10017724  0.10056877\n",
      "   0.09961468]\n",
      " [ 0.10035914  0.09938388  0.09993573 ...,  0.10017724  0.10056877\n",
      "   0.09961468]\n",
      " [ 0.10035914  0.09938388  0.09993573 ...,  0.10017724  0.10056877\n",
      "   0.09961468]] (30.903 sec)\n",
      "INFO:tensorflow:loss = 2.30293, step = 1501 (61.814 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c5100028f3bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c5100028f3bd>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(unused_argv)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#number of times the training loop in your learning algorithm will run to update the parameters in the model. In each loop iteration, it will process a chunk of data, which is basically a batch. Usually, this loop is based on the Gradient Descent algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         hooks=[logging_hook])\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;31m########## Train ##########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    893\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_integer('batch_size', 128,\"Number of images to process in a batch.\")\n",
    "tf.app.flags.DEFINE_integer('epoch', 40,\"Number of epoch\")\n",
    "\n",
    "def weight_variable(shape, w=0.1):\n",
    "    initial = tf.truncated_normal(shape, stddev=w) #Outputs random values from a truncated normal distribution.\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, w=0.1):\n",
    "    initial = tf.constant(w, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \n",
    "#   \"\"\"Model function for CNN.\"\"\"\n",
    "  \n",
    "    # Input Layer\n",
    "    # input layer shape should be [batch_size, image_width, image_height, channels] for conv2d\n",
    "    # set batch_size = -1 means batch_size = the number of input\n",
    "    print('input data shape: ', features[\"x\"])\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 32, 32, 3])\n",
    "    print('input layer shape: ',input_layer.shape)\n",
    "    # conv1\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel = weight_variable(shape=[5, 5, 3, 64]) #shape=[filter_height * filter_width * in_channels, output_channels]\n",
    "        conv = tf.nn.conv2d(input_layer, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = bias_variable(shape=[64], w=0.0)\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "    # pool1\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "    print('pool1 shape: ', pool1)\n",
    "    # norm1\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "\n",
    "    # conv2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = weight_variable(shape=[5, 5, 64, 64])\n",
    "        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = bias_variable(shape=[64], w=0.1)\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "    # norm2\n",
    "    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2')\n",
    "    # pool2\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "    print('pool2 shape: ', pool2)\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2, [-1, 8*8*64])\n",
    "    dense1 = tf.layers.dense(\n",
    "        inputs=pool2_flat,\n",
    "        units=1024, # number of neurons in the dense layer\n",
    "        activation=tf.nn.relu)\n",
    "    dropout1 = tf.layers.dropout(\n",
    "        inputs=dense1,\n",
    "        rate=0.4,\n",
    "        training= mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    dense2 = tf.layers.dense(\n",
    "        inputs=dropout1,\n",
    "        units=1024, # number of neurons in the dense layer\n",
    "        activation=tf.nn.relu)\n",
    "    dropout2 = tf.layers.dropout(\n",
    "        inputs=dense2,\n",
    "        rate=0.4,\n",
    "        training= mode==tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout2, units=10)\n",
    "#     predictions = {\n",
    "#       # Generate predictions (for PREDICT and EVAL mode)\n",
    "#       \"classes\": tf.argmax(input=logits, axis=1),\n",
    "#       # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "#       # `logging_hook`.\n",
    "#       \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "#     }\n",
    "#     # local3\n",
    "#     with tf.variable_scope('local3') as scope:\n",
    "#     # Move everything into depth so we can perform a single matrix multiply.\n",
    "#         print('pool2 shape: ', pool2.shape)\n",
    "#         reshape = tf.reshape(pool2, [-1, 8*8*64])\n",
    "        \n",
    "#         dim = reshape.get_shape()[1].value\n",
    "#         weights = weight_variable(shape=[dim, 384])\n",
    "        \n",
    "#         biases = bias_variable(shape=[384],w=0.1)\n",
    "#         local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "\n",
    "#     # local4\n",
    "#     with tf.variable_scope('local4') as scope:\n",
    "#         weights = weight_variable(shape=[384, 192])\n",
    "#         biases = bias_variable(shape=[192])\n",
    "#         local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "\n",
    "#     # linear layer(WX + b),\n",
    "#     # We don't apply softmax here because\n",
    "#     # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
    "#     # and performs the softmax internally for efficiency.\n",
    "#     with tf.variable_scope('softmax_linear') as scope:\n",
    "#         weights = weight_variable(shape=[192, 10])\n",
    "#         biases = bias_variable(shape=[10])\n",
    "#         logits = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "      onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "            return dict # return dic keys: [b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data']\n",
    "def main(unused_argv):\n",
    "    ########## Data ##########\n",
    "    # Data format:\n",
    "    # data -- a 10000x3072 numpy array of uint8s. \n",
    "    #         Each row of the array stores a 32x32 colour image. \n",
    "    #         The first 1024 entries contain the red channel values, \n",
    "    #         the next 1024 the green, and the final 1024 the blue. \n",
    "    #         The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "    # labels -- a list of 10000 numbers in the range 0-99. The number at index i indicates the label of the ith image in the array data.\n",
    "\n",
    "    # Load training data\n",
    "    train_data = np.empty((0,3072))\n",
    "    train_labels = np.empty((0,))\n",
    "    for i in range(5):\n",
    "        print('Getting data from batch', i+1)\n",
    "        file = './Data/cifar-10/data_batch_'+str(i+1)\n",
    "        train_set = unpickle(file)\n",
    "        train_data = np.concatenate((train_data,train_set[b'data']), axis=0) # shape (50000, 3072) 50000 images of 32x32x3 values\n",
    "        train_labels = np.concatenate((train_labels,np.asarray(train_set[b'labels'])), axis=0)\n",
    "    \n",
    "    print('Train Data shape: ',train_data.shape)\n",
    "    print('Train Label shape: ', train_labels.shape)\n",
    "    \n",
    "    train_data = np.asarray(train_data, dtype=np.float32)\n",
    "    train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "    \n",
    "    # Load testing data\n",
    "    test_set = unpickle('./Data/cifar-10/test_batch')\n",
    "    eval_data =np.asarray(test_set[b'data'], dtype=np.float32) # shape (10000, 3072) 50000 images of 32x32x3 values\n",
    "    eval_labels = np.asarray(test_set[b'labels'], dtype=np.int32)\n",
    "\n",
    "    ########## Data ##########\n",
    "    \n",
    "    ########## CNN classifier ##########\n",
    "    cifar_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"./tmp/mnist_classifier\")\n",
    "    ########## CNN classifier ##########\n",
    "    \n",
    "    ########## Train ##########\n",
    "    # Set up logging for predictions\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "          tensors=tensors_to_log, every_n_iter=50)\n",
    "    \n",
    "    print('batch size: ',FLAGS.batch_size)\n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": train_data},\n",
    "        y=train_labels,\n",
    "        batch_size=FLAGS.batch_size, # number of data in a minibatch\n",
    "        num_epochs=FLAGS.epoch,\n",
    "        shuffle=True) # shuffle training data\n",
    "    cifar_classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=20000, #number of times the training loop in your learning algorithm will run to update the parameters in the model. In each loop iteration, it will process a chunk of data, which is basically a batch. Usually, this loop is based on the Gradient Descent algorithm.\n",
    "        hooks=[logging_hook])\n",
    "    ########## Train ##########\n",
    "    \n",
    "    ########## Evaluate ##########\n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": eval_data},\n",
    "        y=eval_labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    eval_results = cifar_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)\n",
    "    ########## Evaluate ##########\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-tensorflow",
   "language": "python",
   "name": "my-virtualenv-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
