{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### loading word2vec model #####\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import get_data\n",
    "from Word2Vec import Word2Vec_Model\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "########## Hyperparameter ##########\n",
    "BATCH_SIZE = 20\n",
    "VALIDATION_SIZE = 500\n",
    "EPOCH_BOUND = 1000\n",
    "EARLY_STOP_CHECK_EPOCH = 20\n",
    "TAKE_CROSS_VALIDATION = False\n",
    "CROSS_VALIDATION = 5\n",
    "TEXT_EMBEDDING_SIZE = 300\n",
    "MARGIN = 0.1\n",
    "EPOCH_PER_DECAY = 10\n",
    "STORED_PATH = \"./devise_model/devise.ckpt\"\n",
    "########## Hyperparameter ##########\n",
    "\n",
    "########## load Word2Vec model ##########\n",
    "# TextEmbeddings = TextEmbeddings(word2vec_model_path=\"./Data/glove.6B/glove.6B.50d.txt\")\n",
    "# all_text_embedding = TextEmbeddings.load_light_word2vec()\n",
    "# W2V_texts = np.array(list(all_text_embedding.keys()), dtype=np.str)\n",
    "# print('W2V_texts', W2V_texts.shape)\n",
    "\n",
    "TextEmbeddings = Word2Vec_Model(word2vec_model_path=\"./Data/wiki.en.vec\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load Word2Vec model ##########\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = graph_def\n",
    "    #strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "\n",
    "def weight_variable(shape, w=0.1):\n",
    "    initial = tf.truncated_normal(shape, stddev=w) #Outputs random values from a truncated normal distribution.\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, w=0.1):\n",
    "    initial = tf.constant(w, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def devise_model(features, labels, train_mode):\n",
    "    # Input Layer\n",
    "    # input layer shape should be [batch_size, image_width, image_height, channels] for conv2d\n",
    "    # set batch_size = -1 means batch_size = the number of input\n",
    "    print('input data shape: ', features)\n",
    "    input_layer = tf.reshape(features, [-1, 32, 32, 3])\n",
    "    print('input layer shape: ', input_layer.shape)\n",
    "    \n",
    "    ########## Core Visual Model ##########\n",
    "    # conv1\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel = weight_variable(shape=[5, 5, 3, 64]) #shape=[filter_height * filter_width * in_channels, output_channels]\n",
    "        conv = tf.nn.conv2d(input_layer, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = bias_variable(shape=[64], w=0.0)\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "       \n",
    "    # pool1\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    # norm1\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "    # conv2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = weight_variable(shape=[5, 5, 64, 64])\n",
    "        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = bias_variable(shape=[64], w=0.1)\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    # pool2    \n",
    "    pool2 = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "    # norm2\n",
    "    norm2 = tf.nn.lrn(pool2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "    \n",
    "    pool2_flat = tf.reshape(norm2, [-1, 8*8*64])\n",
    "    dense1 = tf.layers.dense(\n",
    "        inputs=pool2_flat,\n",
    "        units=1024, # number of neurons in the dense layer\n",
    "        activation=tf.nn.relu,\n",
    "        name='dense1')\n",
    "    dropout1 = tf.layers.dropout(\n",
    "        inputs=dense1,\n",
    "        rate=0.1,\n",
    "        training= train_mode,\n",
    "        name='dropout1')\n",
    "    dense2 = tf.layers.dense(\n",
    "        inputs=dropout1,\n",
    "        units=512, # number of neurons in the dense layer\n",
    "        activation=tf.nn.relu,\n",
    "        name='dense2')\n",
    "    dropout2 = tf.layers.dropout(\n",
    "        inputs=dense2,\n",
    "        rate=0.1,\n",
    "        training= train_mode,\n",
    "        name='dropout2')\n",
    "    ########## Core Visual Model ##########\n",
    "    \n",
    "    ########## Transformation ##########\n",
    "    visual_embeddings = tf.layers.dense(inputs=dropout2, units=TEXT_EMBEDDING_SIZE, name='transform')\n",
    "    tf.summary.histogram('visual_embeddings', visual_embeddings)\n",
    "    ########## Transformation ##########\n",
    "    \n",
    "    return visual_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_fine_train, y_coarse_train, X_validate, y_fine_validate, y_coarse_validate\n",
    "                        , train_op, epoch_bound, stop_threshold, batch_size, testing=True):\n",
    "\n",
    "    global saver, loss\n",
    "    global writer, merged\n",
    "    \n",
    "    early_stop = 0\n",
    "    best_loss = np.infty\n",
    "    \n",
    "    for epoch in range(epoch_bound):\n",
    "\n",
    "        # randomize training set\n",
    "        indices_training = np.random.permutation(X_train.shape[0])\n",
    "        X_train, y_fine_train, y_coarse_train = X_train[indices_training,:], y_fine_train[indices_training,:], y_coarse_train[indices_training,:]\n",
    "\n",
    "        # split training set into multiple mini-batches and start training        \n",
    "        total_batches = int(X_train.shape[0] / batch_size)\n",
    "        for batch in range(total_batches):\n",
    "            if batch == total_batches - 1:\n",
    "                sess.run(train_op, feed_dict={x: X_train[batch*batch_size:], \n",
    "                                               y1: y_coarse_train[batch*batch_size:],\n",
    "                                               y2: y_fine_train[batch*batch_size:], \n",
    "                                               train_mode: True})\n",
    "                summary = sess.run(merged, feed_dict={x: X_train[batch*batch_size:],\n",
    "                                                      y1: y_coarse_train[batch*batch_size:],\n",
    "                                                      y2: y_fine_train[batch*batch_size:],\n",
    "                                                      train_mode: True})\n",
    "                writer.add_summary(summary, epoch + (batch/total_batches))\n",
    "\n",
    "\n",
    "            else:\n",
    "                sess.run(train_op, feed_dict={x: X_train[batch*batch_size : (batch+1)*batch_size], \n",
    "                                               y1: y_coarse_train[batch*batch_size : (batch+1)*batch_size],\n",
    "                                               y2: y_fine_train[batch*batch_size : (batch+1)*batch_size],\n",
    "                                               train_mode: True})\n",
    "                summary = sess.run(merged, feed_dict={x: X_train[batch*batch_size : (batch+1)*batch_size],\n",
    "                                                      y1: y_coarse_train[batch*batch_size : (batch+1)*batch_size],\n",
    "                                                      y2: y_fine_train[batch*batch_size : (batch+1)*batch_size],\n",
    "                                                      train_mode: True})\n",
    "                writer.add_summary(summary, epoch + (batch/total_batches))\n",
    "\n",
    "        # split validation set into multiple mini-batches and start validating\n",
    "        cur_loss = 0.0\n",
    "        total_batches = int(X_validate.shape[0] / batch_size)\n",
    "        for batch in range(total_batches):\n",
    "            \n",
    "            if batch == total_batches - 1:\n",
    "                cur_loss += sess.run(loss, feed_dict={x:X_validate[batch*batch_size:],\n",
    "                                                      y1:y_coarse_validate[batch*batch_size:],\n",
    "                                                      y2:y_fine_validate[batch*batch_size:],\n",
    "                                                      train_mode: False})\n",
    "            else:\n",
    "                cur_loss += sess.run(loss, feed_dict={x:X_validate[batch*batch_size : (batch+1)*batch_size],\n",
    "                                                      y1:y_coarse_validate[batch*batch_size : (batch+1)*batch_size],\n",
    "                                                      y2:y_fine_validate[batch*batch_size : (batch+1)*batch_size],\n",
    "                                                      train_mode: False})\n",
    "        cur_loss /= total_batches\n",
    "        \n",
    "        # #test for prediction\n",
    "        # prediction = sess.run(predictions, feed_dict={x:X_validate, y:y_validate, mode:'EVAL'})\n",
    "        # print('Predic nearest neighbor: ', prediction['nearest_neighbors'])\n",
    "        \n",
    "        # If the loss does not decrease for many times, it will early stop epochs-loop \n",
    "        if best_loss > cur_loss:\n",
    "            early_stop = 0\n",
    "            best_loss = cur_loss\n",
    "            # save best model in testing phase\n",
    "            if testing == True:\n",
    "                save_path = saver.save(sess, STORED_PATH)\n",
    "        else:\n",
    "            early_stop += 1\n",
    "        print('\\tEpoch: ', epoch, '\\tBest loss: ', best_loss, '\\tCurrent loss: ', cur_loss)\n",
    "        if early_stop == stop_threshold:\n",
    "            break\n",
    "\n",
    "    return best_loss\n",
    "\n",
    "def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "            return dict # return dic keys: [b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data']\n",
    "        \n",
    "def labels_2_embeddings(labels_idx, ref):\n",
    "    \"\"\" Get text embeddings of labels from Text embedding lookup table\n",
    "        label(i) = ref[labels_idx[i]]\n",
    "    Argument: \n",
    "        labels_idx : a list of indices that should refers to ref\n",
    "        ref: a list of labels\n",
    "    Return:\n",
    "        labels_embeddings: a list of text embeddings\n",
    "    \"\"\"\n",
    "    global TextEmbeddings, TEXT_EMBEDDING_SIZE\n",
    "    \n",
    "    labels_embeddings = []\n",
    "    for i in labels_idx:\n",
    "        labels_embeddings.append(TextEmbeddings.text_embedding_lookup(TEXT_EMBEDDING_SIZE, ref[i]))\n",
    "    labels_embeddings = np.array(labels_embeddings, dtype=np.float32)\n",
    "    \n",
    "    return labels_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(fpath):\n",
    "    import sys\n",
    "    from six.moves import cPickle\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "    Arguments:\n",
    "      fpath: path the file to parse.\n",
    "      label_key: key for label data in the retrieve\n",
    "          dictionary.\n",
    "    Returns:\n",
    "      A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    f = open(fpath, 'rb')\n",
    "    if sys.version_info < (3,):\n",
    "        d = cPickle.load(f)\n",
    "    else:\n",
    "        d = cPickle.load(f, encoding='bytes')\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode('utf8')] = v\n",
    "        d = d_decoded\n",
    "    f.close()\n",
    "    data = d['data']\n",
    "    fine_labels = d['fine_labels']\n",
    "    coarse_labels = d['coarse_labels']\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, fine_labels, coarse_labels\n",
    "\n",
    "\n",
    "def load_data(label_mode='fine', path='./Data/cifar-100'):\n",
    "    \"\"\"Loads CIFAR100 dataset.\n",
    "    Arguments:\n",
    "      Pata path.\n",
    "    Returns:\n",
    "      Tuple of Numpy arrays: `(x_train, y_train_fine_label, y_train_coarse_label), (x_test, y_test_fine_label, y_test_coarse_label)`.\n",
    "    Raises:\n",
    "      ValueError: in case of invalid `label_mode`.\n",
    "    \"\"\"\n",
    "    if label_mode not in ['fine', 'coarse', 'both']:\n",
    "        raise ValueError('label_mode must be one of \"fine\", \"coarse\", \"both\"')\n",
    "\n",
    "    fpath = os.path.join(path, 'train')\n",
    "    x_train, y_train_fine_label, y_train_coarse_label = load_batch(fpath)\n",
    "\n",
    "    fpath = os.path.join(path, 'test')\n",
    "    x_test, y_test_fine_label, y_test_coarse_label = load_batch(fpath)\n",
    "\n",
    "    y_train_fine_label = np.reshape(y_train_fine_label, (len(y_train_fine_label)))\n",
    "    y_train_coarse_label = np.reshape(y_train_coarse_label, (len(y_train_coarse_label)))\n",
    "    y_test_fine_label = np.reshape(y_test_fine_label, (len(y_test_fine_label)))\n",
    "    y_test_coarse_label = np.reshape(y_test_coarse_label, (len(y_test_coarse_label)))\n",
    "\n",
    "    x_train = x_train.transpose(0, 2, 3, 1)\n",
    "    x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "    if label_mode=='fine':\n",
    "        return  (x_train, y_train_fine_label), (x_test, y_test_fine_label)\n",
    "    elif label_mode=='coarse':\n",
    "        return (x_train, y_train_coarse_label), (x_test, y_test_coarse_label)\n",
    "    else:\n",
    "        return (x_train, y_train_fine_label, y_train_coarse_label), (x_test, y_test_fine_label, y_test_coarse_label)\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict # return dic keys: [b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aquatic_mammals' 'fish' 'flowers' 'food_containers'\n",
      " 'fruit_and_vegetables' 'household_electrical_devices'\n",
      " 'household_furniture' 'insects' 'large_carnivores' 'large_outdoor_things'\n",
      " 'large_natural_outdoor_scenes' 'large_omnivores_and_herbivores'\n",
      " 'medium_mammals' 'invertebrates' 'people' 'reptiles' 'small_mammals'\n",
      " 'trees' 'vehicles' 'vehicles']\n",
      "Train Data shape:  (50000, 3072)\n",
      "Train Fine Label shape:  (50000,)\n",
      "Train Coarse Label shape: (50000,)\n"
     ]
    }
   ],
   "source": [
    "########## Data ##########\n",
    "# Data format:\n",
    "# data -- a 10000x3072 numpy array of uint8s. \n",
    "#         Each row of the array stores a 32x32 colour image. \n",
    "#         The first 1024 entries contain the red channel values, \n",
    "#         the next 1024 the green, and the final 1024 the blue. \n",
    "#         The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "# labels -- a list of 10000 numbers in the range 0-99. The number at index i indicates the label of the ith image in the array data.\n",
    "\n",
    "# Load training and testing data\n",
    "(train_data, y_train_fine_labels, y_train_coarse_labels), (eval_data, y_eval_fine_labels, y_eval_coarse_labels) = load_data(label_mode='both',path='./Data/cifar-100/')\n",
    "train_data = train_data.reshape(train_data.shape[0], 32*32*3)\n",
    "eval_data = eval_data.reshape(eval_data.shape[0], 32*32*3)\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "train_data = train_data / 255.0\n",
    "eval_data = eval_data / 255.0\n",
    "\n",
    "# 100 labels of cifar-100\n",
    "# cifar-100 class list\n",
    "# fine_labels: 100 labels of classes\n",
    "# coarse_labels: 20 labels of super classes\n",
    "classes = unpickle('./Data/cifar-100/meta')\n",
    "FINE_CLASSES = np.asarray(classes[b'fine_label_names'], dtype=np.dtype(np.str))\n",
    "COARSE_CLASSES = np.asarray(classes[b'coarse_label_names'], dtype=np.dtype(np.str))\n",
    "COARSE_CLASSES[-1]='vehicles'\n",
    "COARSE_CLASSES[-2]='vehicles'\n",
    "COARSE_CLASSES[9]='large_outdoor_things'\n",
    "COARSE_CLASSES[-7]='invertebrates'\n",
    "\n",
    "print(COARSE_CLASSES)\n",
    "train_fine_labels_embeddings = labels_2_embeddings(y_train_fine_labels, FINE_CLASSES)\n",
    "train_coarse_labels_embeddings = labels_2_embeddings(y_train_coarse_labels, COARSE_CLASSES)\n",
    "\n",
    "eval_fine_labels_embeddings = labels_2_embeddings(y_eval_fine_labels, FINE_CLASSES)\n",
    "eval_coarse_labels_embeddings = labels_2_embeddings(y_eval_coarse_labels, COARSE_CLASSES)\n",
    "\n",
    "fine_classes_text_embedding = TextEmbeddings.get_classes_text_embedding(TEXT_EMBEDDING_SIZE, FINE_CLASSES)\n",
    "coarse_classes_text_embedding = TextEmbeddings.get_classes_text_embedding(TEXT_EMBEDDING_SIZE, COARSE_CLASSES)\n",
    "\n",
    "print('Train Data shape: ',train_data.shape)\n",
    "print('Train Fine Label shape: ', y_train_fine_labels.shape)\n",
    "print('Train Coarse Label shape:', y_train_coarse_labels.shape)\n",
    "########## Data ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss defined\n"
     ]
    }
   ],
   "source": [
    "########## devise classifier ##########\n",
    "# x = tf.placeholder(tf.float32, [None, train_data.shape[1]], name='x')\n",
    "\n",
    "# mode = tf.placeholder(tf.string, name='mode')\n",
    "\n",
    "# visual_embeddings = devise_model(x, y, mode)\n",
    "\n",
    "reset_graph()\n",
    "# Transfer layers\n",
    "pretrained_model_path = \"./saved_model/cifar100_simpleCNN/cifar-100_simpleCNN\"\n",
    "# Get graph from pretrained visual model\n",
    "pretrained_saver = tf.train.import_meta_graph(pretrained_model_path + \".ckpt.meta\")\n",
    "#print(tf.get_default_graph().get_operations())\n",
    "\n",
    "# Get variables of cifar-100 cnn model\n",
    "x = tf.get_default_graph().get_tensor_by_name(\"x:0\")\n",
    "train_mode = tf.get_default_graph().get_tensor_by_name(\"train_mode:0\")\n",
    "cnn_output = tf.get_default_graph().get_tensor_by_name(\"dropout1/cond/Merge:0\")\n",
    "\n",
    "# Define new input label placeholder: y1 for super class labels, y2 for fine class labels\n",
    "y1 = tf.placeholder(tf.float32, [None, train_coarse_labels_embeddings.shape[1]], name='y1')\n",
    "y2 = tf.placeholder(tf.float32, [None, train_fine_labels_embeddings.shape[1]], name='y')\n",
    "\n",
    "tf.summary.histogram('cnn_output', cnn_output)\n",
    "\n",
    "# attach transform layer\n",
    "with tf.name_scope('transform'):\n",
    "    visual_embeddings = tf.layers.dense(inputs=cnn_output, units=TEXT_EMBEDDING_SIZE, name='transform')\n",
    "    tf.summary.histogram('visual_embeddings', visual_embeddings)\n",
    "\n",
    "# get training parameter in transform layer for training operation\n",
    "training_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"transform\")\n",
    "\n",
    "# Calculate Loss (for both TRAIN and EVAL modes)\n",
    "## Origine DeViSE defined hinge rank loss\n",
    "# with tf.name_scope('devise_loss'):\n",
    "#     loss = tf.constant(0.0)\n",
    "#     predic_true_distance = tf.reduce_sum(tf.multiply(y, visual_embeddings), axis=1, keep_dims=True)\n",
    "#     for j in range(len(classes_text_embedding)):\n",
    "#         loss = tf.add(loss, tf.maximum(0.0, (MARGIN - predic_true_distance \n",
    "#                                     + tf.reduce_sum(tf.multiply(classes_text_embedding[j], visual_embeddings),axis=1, keep_dims=True))))\n",
    "#     loss = tf.subtract(loss, MARGIN)\n",
    "#     loss = tf.reduce_sum(loss)\n",
    "#     loss = tf.div(loss, BATCH_SIZE)\n",
    "#     tf.summary.scalar('loss', loss)\n",
    "\n",
    "## New loss: Hierachicical hinge rank loss\n",
    "with tf.name_scope('devise_loss'):\n",
    "    loss = tf.constant(0.0)\n",
    "    \n",
    "    ### (H1) Coarse labels hinge rank loss\n",
    "    predic_true_distance = tf.reduce_sum(tf.multiply(y1, visual_embeddings), axis=1, keep_dims=True)\n",
    "    for j in range(len(coarse_classes_text_embedding)):\n",
    "        loss = tf.add(loss, tf.maximum(0.0, (MARGIN - predic_true_distance \n",
    "                                    + tf.reduce_sum(tf.multiply(coarse_classes_text_embedding[j], visual_embeddings),axis=1, keep_dims=True))))\n",
    "    h1_loss = tf.subtract(loss, MARGIN)\n",
    "    h1_loss = tf.reduce_sum(loss)\n",
    "    h1_loss = tf.div(loss, BATCH_SIZE)\n",
    "    \n",
    "    ### (H2) Fine labels hinge rank loss\n",
    "    predic_true_distance = tf.reduce_sum(tf.multiply(y2, visual_embeddings), axis=1, keep_dims=True)\n",
    "    for j in range(len(fine_classes_text_embedding)):\n",
    "        loss = tf.add(loss, tf.maximum(0.0, (MARGIN - predic_true_distance \n",
    "                                    + tf.reduce_sum(tf.multiply(fine_classes_text_embedding[j], visual_embeddings),axis=1, keep_dims=True))))\n",
    "    h2_loss = tf.subtract(loss, MARGIN)\n",
    "    h2_loss = tf.reduce_sum(loss)\n",
    "    h2_loss = tf.div(loss, BATCH_SIZE)\n",
    "    \n",
    "    ### loss = alpha*H1 + beta*H2\n",
    "    loss = 0.5*h1_loss + 0.5*h2_loss\n",
    "    \n",
    "    tf.summary.scalar('loss', loss)\n",
    "    \n",
    "print(\"loss defined\")\n",
    "\n",
    "# Define optimizer and Training iteration (for TRAIN)\n",
    "## Decaying learning rate exponentially based on the total training step\n",
    "\n",
    "decay_steps = int(BATCH_SIZE * EPOCH_PER_DECAY) # Define decay steps\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "        learning_rate=0.01, #initial learning rate\n",
    "        global_step=global_step,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True,\n",
    "        name='ExponentialDecayLearningRate'\n",
    "    )\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate, name='GD_Optimizer')\n",
    "train_op = optimizer.minimize(loss, name='train_op', var_list=training_vars)\n",
    "# ## exponential moving average\n",
    "# ema = tf.train.ExponentialMovingAverage(decay=0.9999)\n",
    "\n",
    "# with tf.control_dependencies([train_op]):\n",
    "#       train_op = ema.apply(training_vars) # apply exponential moving average to training operation\n",
    "\n",
    "########## devise classifier ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Start training ##########\n",
      "X_train[0]:  [ 1.          1.          1.         ...,  0.31372549  0.31372549\n",
      "  0.31372549]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'y' with dtype int32 and shape [?]\n\t [[Node: y = Placeholder[dtype=DT_INT32, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: devise_loss/add_120/_519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1280_devise_loss/add_120\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'y', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-7a1a46bc6a44>\", line 12, in <module>\n    pretrained_saver = tf.train.import_meta_graph(pretrained_model_path + \".ckpt.meta\")\n  File \"/home/shunhuai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1810, in import_meta_graph\n    **kwargs)\n  File \"/home/shunhuai/.local/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 660, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/home/shunhuai/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\n    op_def=op_def)\n  File \"/home/shunhuai/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/shunhuai/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'y' with dtype int32 and shape [?]\n\t [[Node: y = Placeholder[dtype=DT_INT32, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: devise_loss/add_120/_519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1280_devise_loss/add_120\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'y' with dtype int32 and shape [?]\n\t [[Node: y = Placeholder[dtype=DT_INT32, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: devise_loss/add_120/_519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1280_devise_loss/add_120\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c6b49124ffd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# start training with all the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m best_loss = train(X_train, y_fine_train, y_coarse_train, X_validate, y_fine_validate, y_coarse_validate\n\u001b[0;32m---> 32\u001b[0;31m                         , train_op, EPOCH_BOUND, EARLY_STOP_CHECK_EPOCH, BATCH_SIZE, testing=True)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training with all the inputs, loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2a1ab619e661>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_train, y_fine_train, y_coarse_train, X_validate, y_fine_validate, y_coarse_validate, train_op, epoch_bound, stop_threshold, batch_size, testing)\u001b[0m\n\u001b[1;32m     37\u001b[0m                                                       \u001b[0my1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_coarse_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                                       \u001b[0my2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_fine_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                                                       train_mode: True})\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'y' with dtype int32 and shape [?]\n\t [[Node: y = Placeholder[dtype=DT_INT32, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: devise_loss/add_120/_519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1280_devise_loss/add_120\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'y', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-7a1a46bc6a44>\", line 12, in <module>\n    pretrained_saver = tf.train.import_meta_graph(pretrained_model_path + \".ckpt.meta\")\n  File \"/home/shunhuai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1810, in import_meta_graph\n    **kwargs)\n  File \"/home/shunhuai/.local/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 660, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/home/shunhuai/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\n    op_def=op_def)\n  File \"/home/shunhuai/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/shunhuai/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'y' with dtype int32 and shape [?]\n\t [[Node: y = Placeholder[dtype=DT_INT32, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: devise_loss/add_120/_519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1280_devise_loss/add_120\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "########## Train ##########\n",
    "print(\"########## Start training ##########\")\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "# init saver to save model\n",
    "saver = tf.train.Saver()\n",
    "# visualize data\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"logs/cifar100_simpleCNN_devise\", sess.graph)\n",
    "\n",
    "# init weights\n",
    "sess.run(init)\n",
    "# restore value from pretrained model\n",
    "pretrained_saver.restore = (sess, pretrained_model_path + \".ckpt\")\n",
    "for var in training_vars:\n",
    "    sess.run(var.initializer)\n",
    "    \n",
    "# randomize dataset\n",
    "indices = np.random.permutation(train_data.shape[0])\n",
    "Inputs = np.array(train_data[indices,:])\n",
    "Fine_Labels = np.array(train_fine_labels_embeddings[indices,:])\n",
    "Coarse_Labels = np.array(train_coarse_labels_embeddings[indices,:])\n",
    "\n",
    "# get validation set with the size of a batch for early-stop\n",
    "X_train, y_fine_train, y_coarse_train = Inputs[VALIDATION_SIZE:], Fine_Labels[VALIDATION_SIZE:], Coarse_Labels[VALIDATION_SIZE:]\n",
    "X_validate, y_fine_validate, y_coarse_validate = Inputs[:VALIDATION_SIZE], Fine_Labels[:VALIDATION_SIZE], Coarse_Labels[:VALIDATION_SIZE]\n",
    "\n",
    "print('X_train[0]: ', X_train[0])\n",
    "\n",
    "# start training with all the inputs\n",
    "best_loss = train(X_train, y_fine_train, y_coarse_train, X_validate, y_fine_validate, y_coarse_validate\n",
    "                        , train_op, EPOCH_BOUND, EARLY_STOP_CHECK_EPOCH, BATCH_SIZE, testing=True)\n",
    "print(\"training with all the inputs, loss:\", best_loss)\n",
    "\n",
    "sess.close()\n",
    "########## Train ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Evaluate ##########\n",
    "# Evaluate the model and print results\n",
    "print(\"########## Start evaluating ##########\")\n",
    "sess = tf.Session()\n",
    "# restore the precious best model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, STORED_PATH)\n",
    "\n",
    "hit = 0\n",
    "for i in range(10):\n",
    "    predict_embeddings = sess.run(visual_embeddings, feed_dict={x:eval_data[i*1000:(i+1)*1000], y1:eval_coarse_labels_embeddings[i*1000:(i+1)*1000], y2:eval_fine_labels_embeddings[i*1000:(i+1)*1000], train_mode: False})\n",
    "    predict_batch_labels = TextEmbeddings.get_nearest_neighbor_labels(predict_embeddings)\n",
    "    print('Predic nearest neighbor: ')\n",
    "    for idx, predict_labels in enumerate(predict_batch_labels):\n",
    "        long_true_label = FINE_CLASSES[eval_labels[idx]] # refer to class labels\n",
    "        print('Predict top 5 labels:', predict_labels, 'True lable:', long_true_label)\n",
    "        \n",
    "        # consider a class name is concated by multiple labels (ex., maple_tree)\n",
    "        true_labels = long_true_label.split('_')\n",
    "        for true in true_labels:\n",
    "            if(true in predict_labels):\n",
    "                hit+=1\n",
    "                print(\"HIT!\")\n",
    "\n",
    "print(\"Test result: Top 5 hit rate\", hit/100, \"%\")\n",
    "\n",
    "#print('Test accuracy: ', testing_accuracy/5)\n",
    "sess.close()\n",
    "######### Evaluate ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
